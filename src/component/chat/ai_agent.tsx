"use client";
import { useState, useRef, useEffect } from "react";
import {
  Box,
  IconButton,
  Paper,
  TextField,
  Typography,
  Divider,
  CircularProgress,
} from "@mui/material";
import CloseIcon from "@mui/icons-material/Close";
import SendIcon from "@mui/icons-material/Send";
import { GoogleGenAI } from "@google/genai";
import systemInstruction from "./system_instruction";
import Book from "./book";

// --- START: MODIFIED COMPONENT ---
export default function ChatHead() {
  const [instruction, setInstruction] = useState("");
  const [open, setOpen] = useState(false);
  const [message, setMessage] = useState("");
  const [isLoading, setIsLoading] = useState(false);
  
  // Adjusted initial history to follow the M-1 flow (Assistant speaks first)
  const [chatHistory, setChatHistory] = useState([
    // Note: The actual first response (M-1) is generated by the AI on the first user query.
    // This initial message is often a placeholder, or you can rely on the M-1 being the first model output.
    // For now, we'll keep your placeholder greeting, but we'll remove it from the API call.
    { role: "assistant", text: "ðŸ‘‹ Hello! I am Mindstride Assistant, how can i help you today?" },
  ]);

  // Load the full system instruction (with dynamic data) once
  useEffect(() => {
    async function loadInstruction() {
      try {
        const data = await systemInstruction();
        setInstruction(data);
        
        // Add the M-1 output to the history immediately after loading the instruction
        // This ensures the conversation starts with the M-1 prompt.
        // We'll trust the AI to generate M-1 on the first call, or you can fetch it here.
        // For simplicity, we'll let the first user input trigger the M-1 response.
      } catch (error) {
        console.error("Error loading system instruction:", error);
      }
    }
    loadInstruction();
  }, []);

  // Ref for auto-scrolling
  const messagesEndRef = useRef<HTMLDivElement | null>(null);

  const scrollToBottom = () => {
    messagesEndRef.current?.scrollIntoView({ behavior: "smooth" });
  };

  useEffect(() => {
    scrollToBottom();
  }, [chatHistory, isLoading]);

  const handlBook = async (patient_name: string, doctor_name:string, book_date:string) =>{
    try{
      await Book(patient_name,doctor_name,book_date)
    }catch(error){
      console.log(error)
    }
  }

  const handleSend = async () => {
    if (!message.trim() || isLoading) return;

    const userMessage = message.trim();
    setMessage(""); // Clear input immediately
    
    // 1. Immediately update the UI state to show the user's message and the 'Thinking...' indicator.
    setChatHistory((prev) => [
        ...prev, 
        { role: "user", text: userMessage }, // User message is visible now
        { role: "assistant", text: "" } // Add a blank placeholder for the streaming response
    ]);
    
    setIsLoading(true);

    // 2. Build the API contents using the previous history and the current user message.
    // NOTE: We must use the 'prev' state or filter the history to ensure we get the full context
    // before the state changes fully commit. Since `chatHistory` closure inside `handleSend` 
    // might be slightly behind, we'll use a functional update approach for safety.

    // Calculate the API contents based on the state *before* the current `handleSend` call.
    // We will ensure the LATEST user message is included explicitly.
    const historyToMap = chatHistory.filter(msg => msg.role === 'user' || msg.role === 'assistant');

    const API_CONTENTS = historyToMap.map(msg => ({
        role: msg.role === 'assistant' ? 'model' : 'user',
        parts: [{ text: msg.text }]
    }));
    
    // Add the current user message to the API payload.
    API_CONTENTS.push({
        role: 'user',
        parts: [{ text: userMessage }]
    });

    let fullAssistantResponse = "";
    
    try {
        // ... (API Client and Config setup remain the same) ...

        const ai = new GoogleGenAI({
            apiKey : process.env.NEXT_PUBLIC_GEMINI_API_KEY
        });
        
        const config = {
            thinkingConfig: {
                thinkingBudget: -1,
            },
            systemInstruction: instruction,
            tools: [
              { googleSearch: {} },
            ], 
        };
        
        const model = 'gemini-2.5-flash';

        // 3. Call the API with the FULL history (API_CONTENTS).
        const response = await ai.models.generateContentStream({
            model,
            config,
            contents: API_CONTENTS,
        });
        
        // 4. Process the streaming response.
        for await (const chunk of response) {
            const chunkText = chunk.text ?? "";
            fullAssistantResponse += chunkText;

            setChatHistory((prev) => {
                const newHistory = [...prev];
                const lastIdx = newHistory.length - 1;
                
                // Update the last message (the blank placeholder)
                // We trust the structure: [..., {role: 'user'}, {role: 'assistant', text: ""}]
                if (newHistory[lastIdx]?.role === "assistant") {
                    newHistory[lastIdx] = { 
                        ...newHistory[lastIdx], 
                        text: fullAssistantResponse 
                    };
                }
                return newHistory;
            });
        }
        
        
        // 5. Finalize the state *after* the stream is complete.
        // If the response was empty (which can happen with function calls), ensure the UI is clean.
        if (fullAssistantResponse === "") {
             setChatHistory((prev) => {
                const newHistory = [...prev];
                const lastIdx = newHistory.length - 1;
                if (newHistory[lastIdx]?.role === "assistant") {
                     newHistory[lastIdx] = { ...newHistory[lastIdx], text: "Booking initiated successfully." };
                }
                return newHistory;
            });
        }


    } catch (error) {
      console.error("Failed to call Gemini API:", error);
      // Remove the empty assistant message and add the error message
      setChatHistory((prev) => {
          // Find the last assistant message (which is the placeholder) and remove it
          const newHistory = prev.slice(0, prev.length - 2); // Remove the user message + placeholder
          return [...newHistory, { role: "error", text: "Oops! Could not connect to the AI service. Please check the console for details." }];
      });
    } finally {
      setIsLoading(false); // Stop loading
    }
  };
  
  // Allows sending message by pressing Enter key
  const handleKeyDown = (e: React.KeyboardEvent<HTMLInputElement>) => {
    if (e.key === 'Enter') {
      handleSend();
    }
  };
// --- END: MODIFIED COMPONENT ---

  return (
    // ... (Your JSX remains the same)
    <Box
      sx={{
        position: "fixed",
        bottom: 24,
        right: 24,
        zIndex: 1000,
      }}
    >
      {/* Chat Box */}
      {open && (
        <Paper
          elevation={8}
          sx={{
            width: 320,
            height: 820,
            mb: 2,
            borderRadius: 3,
            display: "flex",
            flexDirection: "column",
            overflow: "hidden",
            fontFamily: "Inter, sans-serif",
          }}
        >
          {/* Header */}
          <Box
            sx={{
              display: "flex",
              justifyContent: "space-between",
              alignItems: "center",
              bgcolor: "#2196f3", // primary.main color
              color: "white",
              p: 1.5,
            }}
          >
            <Typography fontWeight={600} variant="subtitle1">AI Assistant</Typography>
            <IconButton color="inherit" size="small" onClick={() => setOpen(false)}>
              <CloseIcon />
            </IconButton>
          </Box>

          {/* Messages */}
          <Box sx={{ flex: 1, p: 2, overflowY: "auto" }}>
            {chatHistory.map((msg, index) => {
              const isUser = msg.role === 'user';
              const isError = msg.role === 'error';
              return (
                <Typography 
                  // >>> HYDRATION FIX HERE: Renders as a <div> instead of the default <p> <<<
                  component="div" 
                  key={index} 
                  sx={{ mb: 1, display: 'flex', justifyContent: isUser ? 'flex-end' : 'flex-start',fontSize: '5px' }} 
                  align={isUser ? 'right' : 'left'}
                >
                  <Box
                    sx={{
                      maxWidth: '80%',
                      p: 1,
                      borderRadius: 2,
                      fontSize: '0.6rem',
                      boxShadow: 1,
                      bgcolor: isUser ? '#60A5FA' : isError ? '#FEE2E2' : '#F3F4F6', // Blue-400 / Red-100 / Zinc-100
                      color: isUser ? 'white' : isError ? '#EF4444' : '#1F2937', // White / Red-500 / Gray-800
                      border: isError ? '1px solid #EF4444' : 'none',
                    }}
                  >
                    {msg.text}
                  </Box>
                </Typography>
              );
            })}

            {/* Loading indicator */}
            {isLoading && (
              <Typography component="div" sx={{ mb: 1, display: 'flex', justifyContent: 'flex-start' }}>
                <Box
                  sx={{
                    p: 1,
                    borderRadius: 2,
                    fontSize: '0.875rem',
                    bgcolor: '#F3F4F6',
                    color: '#1F2937',
                    display: 'flex',
                    alignItems: 'center',
                  }}
                >
                  <CircularProgress size={16} sx={{ mr: 1, color: '#9CA3AF' }} />
                  Thinking...
                </Box>
              </Typography>
            )}
            <div ref={messagesEndRef} />
          </Box>
          <Divider />
          {/* Input */}
          <Box sx={{ display: "flex", alignItems: "center", p: 1 }}>
            <TextField
              variant="outlined"
              size="small"
              fullWidth
              placeholder="Type a message..."
              value={message}
              onChange={(e) => setMessage(e.target.value)}
              onKeyDown={handleKeyDown}
              disabled={isLoading}
            />
            <IconButton
              color="primary"
              sx={{ ml: 1 }}
              onClick={handleSend}
              disabled={isLoading || !message.trim()}
            >
              <SendIcon />
            </IconButton>
          </Box>
        </Paper>
      )}

      {/* Floating Button */}
      <IconButton
        color="primary"
        sx={{
          bgcolor: "#2563EB", // Tailwind blue-600
          color: "white",
          "&:hover": { bgcolor: "#1D4ED8" }, // Tailwind blue-700
          boxShadow: 4,
          width: 56,
          height: 56,
          borderRadius: "50%",
        }}
        onClick={() => setOpen(!open)}
      >
        {/* Placeholder Icon - You should replace the image source with a local asset or a suitable MUI Icon */}
        <Box
            component="img"
            src="https://placehold.co/56x56/2563EB/ffffff?text=AI" 
            alt="Chat"
            sx={{ width: "100%", height: "100%", objectFit: "contain", borderRadius: "50%"}}
        />
      </IconButton>
    </Box>
  );
}